{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the data\n",
    "dfspam = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv',encoding='latin-1')\n",
    "dfspam.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspam.drop(['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'],axis=1, inplace=True)\n",
    "dfspam.columns = ['label','message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspam.isnull().sum()#to check if there is any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2283fad8048>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count the spam and ham messages\n",
    "print(dfspam['label'].value_counts())\n",
    "sns.countplot(x='label', data=dfspam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the punctuation\n",
    "import string\n",
    "\n",
    "# Function to remove the punctuation\n",
    "def remove_punct(text):\n",
    "    newtext = ''\n",
    "    for char in text:\n",
    "        if char in string.punctuation:\n",
    "            continue\n",
    "        else:\n",
    "            newtext += char\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message before removing the punctuation:\n",
      "\n",
      "\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "message after removing the punctuation:\n",
      "\n",
      "Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat\n"
     ]
    }
   ],
   "source": [
    "single_message = dfspam['message'][0]\n",
    "\n",
    "print('message before removing the punctuation:')\n",
    "print('\\n')\n",
    "print(single_message)\n",
    "print('\\n')\n",
    "print('message after removing the punctuation:')\n",
    "print()\n",
    "print(remove_punct(single_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspam['message'] = dfspam['message'].apply(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n"
     ]
    }
   ],
   "source": [
    "#converting all text to lowercase\n",
    "def message_lowercase(text):\n",
    "    lowercase_message=''\n",
    "    for message in text:\n",
    "        lowercase_message += message.lower()\n",
    "    return lowercase_message\n",
    "\n",
    "print(message_lowercase(dfspam['message'][0]))#single message to ensure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspam['message'] = dfspam['message'].apply(message_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham        u dun say so early hor u c already then say\n",
       "4   ham  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspam.head()#all messages converted to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform stemming we will use Porterstemmer from nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# Function to do the stemming\n",
    "def stemming(text):\n",
    "    text = text.split(' ') # to seperate the words\n",
    "    text = [p_stemmer.stem(word) for word in text]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message before stemming:\n",
      "\n",
      "\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "\n",
      "\n",
      "message after stemming:\n",
      "\n",
      "['nah', 'i', 'dont', 'think', 'he', 'goe', 'to', 'usf', 'he', 'live', 'around', 'here', 'though']\n"
     ]
    }
   ],
   "source": [
    "# test it on single message\n",
    "single_message = dfspam['message'][4]\n",
    "\n",
    "print('message before stemming:')\n",
    "print('\\n')\n",
    "print(single_message)\n",
    "print('\\n')\n",
    "print('message after stemming:')\n",
    "print()\n",
    "print(stemming(single_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the above function to all the messages\n",
    "dfspam['message'] = dfspam['message'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazi, avail, onli,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, earli, hor, u, c, alreadi, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, dont, think, he, goe, to, usf, he, li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  [go, until, jurong, point, crazi, avail, onli,...\n",
       "1   ham                       [ok, lar, joke, wif, u, oni]\n",
       "2  spam  [free, entri, in, 2, a, wkli, comp, to, win, f...\n",
       "3   ham  [u, dun, say, so, earli, hor, u, c, alreadi, t...\n",
       "4   ham  [nah, i, dont, think, he, goe, to, usf, he, li..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message before removing the stopwords:\n",
      "\n",
      "\n",
      "['nah', 'i', 'dont', 'think', 'he', 'goe', 'to', 'usf', 'he', 'live', 'around', 'here', 'though']\n",
      "\n",
      "\n",
      "message after removing the stopwords:\n",
      "\n",
      "nah dont think goe usf live around though\n"
     ]
    }
   ],
   "source": [
    "# Stopwords can be is,are,the etc.\n",
    "# use stopword method from nltk corpus library\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# function to remove the stopword\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopwords.words('english')]\n",
    "    \n",
    "    # converting the list back to text\n",
    "    return ' '.join(text)\n",
    "\n",
    "# test it on single message\n",
    "single_message = dfspam['message'][4]\n",
    "\n",
    "print('message before removing the stopwords:')\n",
    "print('\\n')\n",
    "print(single_message)\n",
    "print('\\n')\n",
    "print('message after removing the stopwords:')\n",
    "print()\n",
    "print(remove_stopwords(single_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the above function to all the messages\n",
    "dfspam['message'] = dfspam['message'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>G   u n l   j u r n g   p n   c r z   A v l b ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>O k   l r   J k n g   w f   u   n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>F r e e   e n r   n   2     w k l   c p     w ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U   u n       e r l   h r   U   c   l r e   h ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>N h   I   n   h n k   h e   g e     u f   h e ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  G   u n l   j u r n g   p n   c r z   A v l b ...\n",
       "1   ham                  O k   l r   J k n g   w f   u   n\n",
       "2  spam  F r e e   e n r   n   2     w k l   c p     w ...\n",
       "3   ham  U   u n       e r l   h r   U   c   l r e   h ...\n",
       "4   ham  N h   I   n   h n k   h e   g e     u f   h e ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(dfspam['message']).toarray()\n",
    "y = dfspam.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide the data into X and y\n",
    "\n",
    "X = dfspam['message']\n",
    "y = dfspam['label']\n",
    "\n",
    "# Let's perform the one hot encoding for y \n",
    "encoded_y = pd.get_dummies(y,drop_first=True).values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide the data into train and test set. We will take 25% of data as test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,encoded_y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = Pipeline([\n",
    "    ('vector',TfidfVectorizer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vector',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_naive = naive.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of naive model is 96.63%\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1216\n",
      "           1       1.00      0.73      0.85       177\n",
      "\n",
      "    accuracy                           0.97      1393\n",
      "   macro avg       0.98      0.87      0.91      1393\n",
      "weighted avg       0.97      0.97      0.96      1393\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_naive = accuracy_score(y_test,predict_naive)\n",
    "print(f\"Accuracy of naive model is {np.round(acc_naive*100,2)}%\")\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predict_naive))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
